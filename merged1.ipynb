{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14c8361",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Setebos12/Tick-Tac-Go/blob/main/merged1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cjv_ekzjF12M",
   "metadata": {
    "id": "Cjv_ekzjF12M"
   },
   "source": [
    "# Boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e940271",
   "metadata": {
    "id": "5e940271"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d331c",
   "metadata": {
    "id": "410d331c"
   },
   "outputs": [],
   "source": [
    "class AbstractBoard(ABC):\n",
    "    @abstractmethod\n",
    "    def get_neighbours(self, position):\n",
    "        \"\"\"\n",
    "        Returns a list of neighboring positions for the given position.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_neighbour(self, position, direction):\n",
    "        \"\"\"\n",
    "        Returns the neighboring position in the specified direction.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_value(self, position):\n",
    "        \"\"\"\n",
    "        Returns the value at the given position on the board.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def set_value(self, position, value):\n",
    "        \"\"\"\n",
    "        Sets the value at the given position on the board.\n",
    "        This method can be overridden if the board supports setting values.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5884b5c",
   "metadata": {
    "id": "b5884b5c"
   },
   "outputs": [],
   "source": [
    "class GridBoard(AbstractBoard):\n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "        self.rows = len(grid)\n",
    "        self.cols = len(grid[0]) if self.rows > 0 else 0\n",
    "\n",
    "    def get_neighbours(self, position):\n",
    "        x, y = position\n",
    "        neighbours = []\n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                if (dx != 0 or dy != 0) and 0 <= x + dx < self.rows and 0 <= y + dy < self.cols:\n",
    "                    neighbours.append((x + dx, y + dy))\n",
    "        return neighbours\n",
    "\n",
    "    def get_neighbour(self, position, direction):\n",
    "        x, y = position\n",
    "        dx, dy = direction\n",
    "        new_x, new_y = x + dx, y + dy\n",
    "        if 0 <= new_x < self.rows and 0 <= new_y < self.cols:\n",
    "            return (new_x, new_y)\n",
    "        return None\n",
    "\n",
    "    def get_value(self, position):\n",
    "        x, y = position\n",
    "        return self.grid[x][y] if 0 <= x < self.rows and 0 <= y < self.cols else None\n",
    "\n",
    "\n",
    "    def set_value(self, position, value):\n",
    "        x, y = position\n",
    "        if self.check_if_position_board(position):\n",
    "            self.grid[x][y] = value\n",
    "\n",
    "    def check_if_position_board(self, position):\n",
    "        x, y = position\n",
    "        return 0 <= x < self.rows and 0 <= y < self.cols\n",
    "\n",
    "    def __str__(self):\n",
    "        for row in self.grid:\n",
    "            print(\" \".join(map(str, row)))\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e823c02",
   "metadata": {
    "id": "8e823c02"
   },
   "outputs": [],
   "source": [
    "class Board(AbstractBoard):\n",
    "    def __init__(self, neighbours, board):\n",
    "        self.neighbours = neighbours\n",
    "        self.board = board\n",
    "\n",
    "    def get_neigbours(self, position):\n",
    "        \"\"\"\n",
    "        Returns a list of neighboring positions for the given position.\n",
    "        \"\"\"\n",
    "        return self.neighbours.get(position, [])\n",
    "\n",
    "    def get_value(self, position):\n",
    "        \"\"\"\n",
    "        Returns the value at the given position on the board.\n",
    "        \"\"\"\n",
    "        return self.board.get(position)\n",
    "\n",
    "    def set_value(self, position, value):\n",
    "        \"\"\"\n",
    "        Sets the value at the given position on the board.\n",
    "        \"\"\"\n",
    "        self.board[position] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92dbc9",
   "metadata": {
    "id": "cb92dbc9"
   },
   "outputs": [],
   "source": [
    "class DirectionBoard(Board):\n",
    "    def __init__(self, neighbours, board, directions):\n",
    "        super().__init__(neighbours, board)\n",
    "        self.directions = directions\n",
    "\n",
    "    def get_neighbour(self, position, direction):\n",
    "        \"\"\"\n",
    "        Returns the neighboring position in the specified direction.\n",
    "        \"\"\"\n",
    "        if direction in self.directions:\n",
    "            dx, dy = self.directions[direction]\n",
    "            new_x, new_y = position[0] + dx, position[1] + dy\n",
    "            return (new_x, new_y) if (new_x, new_y) in self.board else None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzwMQea41JuS",
   "metadata": {
    "id": "wzwMQea41JuS"
   },
   "source": [
    "# Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138099e",
   "metadata": {
    "id": "0138099e"
   },
   "outputs": [],
   "source": [
    "from types import FunctionType\n",
    "class Player:\n",
    "    def __init__(self, name: str, score: int = 0, symbol: str = None, agent : FunctionType = None):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        self.symbol = symbol\n",
    "        self.agent = agent\n",
    "\n",
    "    def make_move(self, board, position, symbol):\n",
    "        \"\"\"\n",
    "        Make a move on the board at the specified position with the given symbol.\n",
    "        \"\"\"\n",
    "        if board.get_value(position) in [None, '', 0]:\n",
    "            board.set_value(position, symbol)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def make_move_agent(self, *args):\n",
    "      \"\"\"\n",
    "      Make a move on the board at the specified position with the given symbol.\n",
    "      \"\"\"\n",
    "      return self.agent.choose_move(*args)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bMwsSIGtOSRY",
   "metadata": {
    "id": "bMwsSIGtOSRY"
   },
   "source": [
    "# Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccbf01",
   "metadata": {
    "id": "b5ccbf01"
   },
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, board, players = None):\n",
    "        self.players = players\n",
    "        if self.players is None:\n",
    "          self.players = [Player(\"AI\", symbol='X'), Player(\"Bob\", symbol='S')]\n",
    "\n",
    "        self.board = board\n",
    "        self.current_player_index = 0\n",
    "\n",
    "    def switch_player(self):\n",
    "        \"\"\"\n",
    "        Switch to the next player.\n",
    "        \"\"\"\n",
    "        self.current_player_index = (self.current_player_index + 1) % len(self.players)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the game loop.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            current_player = self.players[self.current_player_index]\n",
    "            print(f\"{current_player.name}'s turn\")\n",
    "            print(self.board.grid)\n",
    "            position = self.get_player_move(current_player)\n",
    "            symbol = current_player.symbol\n",
    "\n",
    "            if not current_player.make_move(self.board, position, symbol):\n",
    "                print(\"Invalid move. Try again.\")\n",
    "                continue\n",
    "\n",
    "            if Check_all_positions_directions(self.board, symbol, position):\n",
    "                print(self.board.grid)\n",
    "                print(f\"{current_player.name} wins!\")\n",
    "                break\n",
    "\n",
    "            self.switch_player()\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Evaluate the current game state.\n",
    "        \"\"\"\n",
    "        for player in self.players:\n",
    "            if Check_all_positions_directions(self.board, player.symbol):\n",
    "                return player\n",
    "        return None\n",
    "\n",
    "    def is_terminal_node(self):\n",
    "        \"\"\"\n",
    "        Check if the game is in a terminal state.\n",
    "        \"\"\"\n",
    "        # The game is terminal if there's a winner or the board is full\n",
    "        return self.evaluate() is not None or not self.possible_moves()\n",
    "\n",
    "\n",
    "    def get_player_move(self, player):\n",
    "        \"\"\"\n",
    "        Get the player's move input.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                move = input(f\"{player.name}, enter your move (row,col): \")\n",
    "                row, col = map(int, move.split(','))\n",
    "                if 0 <= row < len(self.board.grid) and 0 <= col < len(self.board.grid[0]):\n",
    "                    return (row, col)\n",
    "                else:\n",
    "                    print(\"Move out of bounds. Try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter row and column as 'row,col'.\")\n",
    "\n",
    "    def possible_moves(self):\n",
    "        \"\"\"\n",
    "        Get a list of possible moves.\n",
    "        \"\"\"\n",
    "        moves = []\n",
    "        for i in range(len(self.board.grid)):\n",
    "            for j in range(len(self.board.grid[0])):\n",
    "                # Check for empty strings, None, or 0 as empty\n",
    "                if self.board.get_value((i, j)) in [None, '', 0]:\n",
    "                    moves.append((i, j))\n",
    "        return moves\n",
    "\n",
    "    def make_move(self, move):\n",
    "        \"\"\"\n",
    "        Make a move on a *copy* of the board and return a *new* Game object.\n",
    "        \"\"\"\n",
    "        self.board.set_value(move, self.players[self.current_player_index].symbol)\n",
    "        self.switch_player()\n",
    "\n",
    "\n",
    "    def deep_copy(self):\n",
    "        \"\"\"\n",
    "        Create a deep copy of the game.\n",
    "        \"\"\"\n",
    "        new_players = [Player(player.name, player.score, player.symbol) for player in self.players]\n",
    "        new_board = GridBoard([row[:] for row in self.board.grid]) # Correctly copy the grid\n",
    "        new_game = Game(new_board)\n",
    "        new_game.players = new_players\n",
    "        new_game.current_player_index = self.current_player_index\n",
    "        return new_game\n",
    "\n",
    "    def current_player(self):\n",
    "      return self.players[self.current_player_index]\n",
    "\n",
    "    def info(self):\n",
    "      info = {\"players\" : len(self.players),\n",
    "              \"turn\" : self.current_player_index,\n",
    "              \"board\": self.board.grid}\n",
    "      return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1NGNAeCfOZyv",
   "metadata": {
    "id": "1NGNAeCfOZyv"
   },
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19410642",
   "metadata": {
    "id": "19410642"
   },
   "outputs": [],
   "source": [
    "def All_same_cryteria(nums, symbol):\n",
    "    for num in nums:\n",
    "        if num != symbol:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c6eb7",
   "metadata": {
    "id": "841c6eb7"
   },
   "outputs": [],
   "source": [
    "def Check_Connection(nums, symbol, position, direction, how_many = 3):\n",
    "    \"\"\"\n",
    "    Check if there is a connection of the same symbol in the specified direction.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(how_many):\n",
    "        if  nums.get_value(position) == symbol:\n",
    "            count += 1\n",
    "            position = (position[0] + direction[0], position[1] + direction[1])\n",
    "        else:\n",
    "            break\n",
    "    return count == how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d40d1",
   "metadata": {
    "id": "823d40d1"
   },
   "outputs": [],
   "source": [
    "def Check_all_directions(nums, symbol, position, directions=None, how_many = 3):\n",
    "    \"\"\"\n",
    "    Check if there is a connection in any of the specified directions.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        directions = [(-1, -1), (-1, 0), (-1, 1),\n",
    "                    (0, -1),           (0, 1),\n",
    "                    (1, -1),  (1, 0),  (1, 1)]\n",
    "    for direction in directions:\n",
    "        if Check_Connection(nums, symbol, position, direction, how_many):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TuI80BILIV2I",
   "metadata": {
    "id": "TuI80BILIV2I"
   },
   "outputs": [],
   "source": [
    "def Check_all_positions_directions(nums, symbol, directions=None, how_many = 3):\n",
    "    \"\"\"\n",
    "    Check if there is a connection in any of the specified directions.\n",
    "    \"\"\"\n",
    "    for i in range(len(nums.grid)):\n",
    "        for j in range(len(nums.grid[0])):\n",
    "            if Check_all_directions(nums, symbol, (i, j)):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NOwL2g_nGgdM",
   "metadata": {
    "id": "NOwL2g_nGgdM"
   },
   "source": [
    "# Node\n",
    "\n",
    "representing each state of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ykB_V4Zzel8i",
   "metadata": {
    "id": "ykB_V4Zzel8i"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, parent=None, move=None):\n",
    "        self.game = game\n",
    "        self.parent = parent\n",
    "        self.move = move\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def add_children(self):\n",
    "        for move in self.game.possible_moves():\n",
    "            new_game = self.game.deep_copy()\n",
    "            new_game.make_move(move)\n",
    "            child = Node(new_game, self, move)\n",
    "            self.add_child(child)\n",
    "\n",
    "    def is_terminal_node(self):\n",
    "        return self.game.is_terminal_node()\n",
    "\n",
    "    def evaluate(self, player = 0):\n",
    "        evaluation = self.game.evaluate()\n",
    "        if isinstance(evaluation, Player):\n",
    "            evaluation1 = 1 if evaluation.symbol == 'X' else -1\n",
    "            if player != 0:\n",
    "                evaluation1 = -evaluation1\n",
    "            return evaluation1\n",
    "        return 0\n",
    "\n",
    "    def state_key(self):\n",
    "        return str(self.game.info())\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.game.info())\n",
    "\n",
    "\n",
    "    def get_parent_move(self):\n",
    "        return self.move ,self.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ll6sbTNnPBaU",
   "metadata": {
    "id": "Ll6sbTNnPBaU"
   },
   "source": [
    "# min max algorythms\n",
    "\n",
    "* normal (brute force)\n",
    "* memotyzation all states\n",
    "* just the best move\n",
    "\n",
    "TO_DO for each postion you get sorted by evaluaion moves\n",
    "\n",
    "\n",
    "Jak sprawdziÄ‡ czy mam juÅ¼ zrobione? i mogÄ™ isc dalej.\n",
    " - napisaÄ‡ testy czy dla kazdej pozycji jest ruch w wymaganym czasie\n",
    " - napisaÄ‡ testy ktÃ³re sprawdzÄ… poprawnoÅ›Ä‡ algorytmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09jfKbjIGhMr",
   "metadata": {
    "id": "09jfKbjIGhMr"
   },
   "outputs": [],
   "source": [
    "def min_max(node, depth, maximizing_player):\n",
    "    if depth == 0 or node.is_terminal_node():\n",
    "        return node.evaluate()\n",
    "\n",
    "    if maximizing_player:\n",
    "        max_eval = -float('inf')\n",
    "        node.add_children()\n",
    "        for child in node.children:\n",
    "            eval = min_max(child, depth - 1, False)\n",
    "            max_eval = max(max_eval, eval)\n",
    "        return max_eval\n",
    "    else:\n",
    "        min_eval = float('inf')\n",
    "        node.add_children()\n",
    "        for child in node.children:\n",
    "            eval = min_max(child, depth - 1, True)\n",
    "            min_eval = min(min_eval, eval)\n",
    "        return min_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2FaMh6EME0h",
   "metadata": {
    "id": "z2FaMh6EME0h"
   },
   "outputs": [],
   "source": [
    "def min_max_remember(node, depth, maximizing_player, memo):\n",
    "    if depth == 0 or node.is_terminal_node():\n",
    "        return node.evaluate(), None\n",
    "\n",
    "\n",
    "    best_move = None\n",
    "\n",
    "    if maximizing_player:\n",
    "        max_eval = -float('inf')\n",
    "        node.add_children()\n",
    "        for child in node.children:\n",
    "            eval, _ = min_max_remember(child, depth - 1, False, memo)\n",
    "            if eval > max_eval:\n",
    "                max_eval = eval\n",
    "                best_move = child.move\n",
    "            add_to_memo(memo,node, child.move, eval, maximizing_player) # Moved inside the loop\n",
    "        return max_eval, best_move\n",
    "\n",
    "    else:\n",
    "        min_eval = float('inf')\n",
    "        node.add_children()\n",
    "        for child in node.children:\n",
    "            eval, _ = min_max_remember(child, depth - 1, True, memo)\n",
    "            if eval < min_eval:\n",
    "                min_eval = eval\n",
    "                best_move = child.move\n",
    "            add_to_memo(memo,node, child.move, eval, maximizing_player) # Moved inside the loop\n",
    "        return min_eval, best_move\n",
    "\n",
    "\n",
    "def add_to_memo(memo,node, move, eval, maximizing_player):\n",
    "  if str(node) not in memo:\n",
    "    memo[str(node)] = [(eval, move)]\n",
    "  else:\n",
    "    if (eval, move) not in memo[str(node)]:\n",
    "      memo[str(node)].append((eval, move))\n",
    "      if maximizing_player:\n",
    "        memo[str(node)].sort(reverse=True)\n",
    "      else:\n",
    "        memo[str(node)].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N8ZU9LORMiXI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8ZU9LORMiXI",
    "lines_to_next_cell": 2,
    "outputId": "723a2877-be65-422a-b291-9adce8cbf8a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, (0, 0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "    node = Node(game)\n",
    "    memo = {}\n",
    "    min_max_remember(node, 10000000, 1, memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uKOK9FzB_elP",
   "metadata": {
    "id": "uKOK9FzB_elP"
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "class memoagent:\n",
    "  def __init__(self, memo):\n",
    "    self.memo = memo\n",
    "    self.is_learning = False\n",
    "\n",
    "  def choose_move(self,node, *args):\n",
    "    moves = memo[str(node)]\n",
    "    best_moves = [move for eval, move in moves if eval == moves[0][0]]\n",
    "    move = choice(best_moves)\n",
    "    return move\n",
    "\n",
    "  def choose_action(self, node, *args):\n",
    "    moves = memo[str(node)]\n",
    "    best_moves = [move for eval, move in moves if eval == moves[0][0]]\n",
    "    move = choice(best_moves)\n",
    "    return move\n",
    "\n",
    "\n",
    "\n",
    "class memoagent1:\n",
    "  def __init__(self, memo):\n",
    "    self.memo = memo\n",
    "\n",
    "  def choose_move(self, game, *args):\n",
    "    node = Node(game)\n",
    "    moves = memo[str(node)]\n",
    "    return moves[0][0]\n",
    "\n",
    "class random_player:\n",
    "  def __init__(self):\n",
    "    self.is_learning = False\n",
    "\n",
    "\n",
    "  def choose_move(self, node, *args):\n",
    "    return choice(node.game.possible_moves())\n",
    "\n",
    "\n",
    "  def choose_action(self, node, *args):\n",
    "    return choice(node.game.possible_moves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d235bf8",
   "metadata": {
    "id": "3d235bf8"
   },
   "outputs": [],
   "source": [
    "def find_best_move(node):\n",
    "    best_eval = -float('inf')\n",
    "    best_move = None\n",
    "    node.add_children()\n",
    "    ans = []\n",
    "    for child in node.children:\n",
    "        eval = min_max(child, 100, False)\n",
    "        if eval > best_eval:\n",
    "            best_eval = eval\n",
    "            best_move = child.move\n",
    "\n",
    "        ans.append((child.move, eval))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d-WUltg7RbCu",
   "metadata": {
    "id": "d-WUltg7RbCu"
   },
   "source": [
    "# Veryfictaion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qr45ppfnU6Us",
   "metadata": {
    "id": "qr45ppfnU6Us"
   },
   "outputs": [],
   "source": [
    "class Veryfication:\n",
    "    def __init__(self, players):\n",
    "        self.players = players\n",
    "        self.results = dict()\n",
    "        self.create_dict()\n",
    "\n",
    "    def create_dict(self):\n",
    "        endings = [\"win\", \"lose\", \"draw\"]\n",
    "        for player in self.players:\n",
    "            self.results[player.name] = {end: 0 for end in endings}\n",
    "\n",
    "    def verify(self, episodes):\n",
    "        for episode in range(episodes):\n",
    "            game = self.setup_game()\n",
    "            self.play_game(game)\n",
    "            self.record_result(game)\n",
    "\n",
    "    def setup_game(self):\n",
    "        grid = [['', '', ''], ['', '', ''], ['', '', '']]\n",
    "        board = GridBoard(grid)\n",
    "        return Game(board, self.players)\n",
    "\n",
    "    def play_game(self, game):\n",
    "        current_player = None\n",
    "        while not game.is_terminal_node():\n",
    "            current_player = game.players[game.current_player_index]\n",
    "            move = current_player.make_move_agent(Node(game))\n",
    "            game.make_move(move)\n",
    "\n",
    "\n",
    "    def record_result(self, game):\n",
    "        who_won = game.evaluate()\n",
    "        if isinstance(who_won, Player):\n",
    "            self.results[who_won.name][\"win\"] += 1\n",
    "            for player in self.players:\n",
    "                if player != who_won:\n",
    "                    self.results[player.name][\"lose\"] += 1\n",
    "        else:\n",
    "            for player in self.players:\n",
    "                self.results[player.name][\"draw\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MTQPDTj8txYZ",
   "metadata": {
    "id": "MTQPDTj8txYZ"
   },
   "outputs": [],
   "source": [
    "class VeryficationV2(Veryfication):\n",
    "  def __init__(self, players):\n",
    "    super().__init__(players)\n",
    "    self.game_history = None\n",
    "\n",
    "\n",
    "  def verify(self, episodes):\n",
    "    for episode in range(episodes):\n",
    "      game = self.setup_game()\n",
    "      self.game_history = GameHistory(game)\n",
    "      self.play_game(game)\n",
    "      self.record_result(game)\n",
    "\n",
    "  def play_game(self, game):\n",
    "      while not game.is_terminal_node():\n",
    "          current_player = game.players[game.current_player_index]\n",
    "          node = self.game_history.get_current()\n",
    "          move = current_player.make_move_agent(node, True)\n",
    "          game.make_move(move)\n",
    "          self.game_history.save_state(game, move)\n",
    "\n",
    "      self.last_round_learn(self.game_history.get_current())\n",
    "\n",
    "  def last_round_learn(self, node):\n",
    "    for player in self.players:\n",
    "      if player.agent.is_learning:\n",
    "        node.game.current_player_index = self.players.index(player)\n",
    "        player.agent.learn_in_game_from_previous_moves(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OiCGuqD90yDK",
   "metadata": {
    "id": "OiCGuqD90yDK"
   },
   "outputs": [],
   "source": [
    "class GameHistory:\n",
    "  def __init__(self, game):\n",
    "    self.begin_node = Node(game)\n",
    "    self.current_node = self.begin_node\n",
    "\n",
    "  def save_state(self, game, move):\n",
    "    new_game = game.deep_copy()\n",
    "    node = Node(new_game, parent=self.current_node, move=move)\n",
    "    self.current_node.add_child(node)\n",
    "    self.current_node = node\n",
    "\n",
    "\n",
    "  def get_current(self):\n",
    "    return self.current_node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yyWYZByy0H0y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyWYZByy0H0y",
    "outputId": "a583f820-e640-407d-8322-c1f4a1109569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 1, 'lose': 0, 'draw': 0},\n",
       " 'Bob': {'win': 0, 'lose': 1, 'draw': 0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", memoagent(memo))\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", random_player())\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(1)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DFuzoBwr1bTC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFuzoBwr1bTC",
    "outputId": "bdd90a4f-c1c3-4515-c3ac-0b08c30860e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'players': 2, 'turn': 1, 'board': [['X', 'X', 'X'], ['S', 'X', ''], ['S', '', 'S']]}\n",
      "{'players': 2, 'turn': 0, 'board': [['X', '', 'X'], ['S', 'X', ''], ['S', '', 'S']]}\n",
      "{'players': 2, 'turn': 1, 'board': [['X', '', 'X'], ['S', 'X', ''], ['S', '', '']]}\n",
      "{'players': 2, 'turn': 0, 'board': [['', '', 'X'], ['S', 'X', ''], ['S', '', '']]}\n",
      "{'players': 2, 'turn': 1, 'board': [['', '', 'X'], ['S', 'X', ''], ['', '', '']]}\n",
      "{'players': 2, 'turn': 0, 'board': [['', '', ''], ['S', 'X', ''], ['', '', '']]}\n",
      "{'players': 2, 'turn': 1, 'board': [['', '', ''], ['', 'X', ''], ['', '', '']]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def retrive_game(game_history):\n",
    "  ans = []\n",
    "  current_node = game_history.current_node\n",
    "  while current_node.parent is not None:\n",
    "    ans.append(current_node.game.info())\n",
    "    print(current_node.game.info())\n",
    "    current_node = current_node.parent\n",
    "  return ans.reverse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "iZuN-lJBeLst",
   "metadata": {
    "id": "iZuN-lJBeLst"
   },
   "source": [
    "# Q algorythm\n",
    ":\n",
    "TO_DO ðŸ‡¹:\n",
    "\n",
    "\n",
    "1.   move Q algorytm to class or funtion ðŸš‚ ðŸš†\n",
    "2.   Test algorytms with min_max and evalution functio ðŸŽ®\n",
    "\n",
    "SUPER TO_DO\n",
    "\n",
    "\n",
    "\n",
    "1.   another types of Q algorytm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TMPofiohGfEL",
   "metadata": {
    "id": "TMPofiohGfEL"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Qagent:\n",
    "  def __init__(self, Q):\n",
    "    self.Q = Q\n",
    "\n",
    "  def choose_move(self, node, *args):\n",
    "    state = node.state_key()\n",
    "    possible_moves = node.game.possible_moves()\n",
    "    q_vals = [self.Q.get((state, a), 0) for a in possible_moves]\n",
    "    max_q = max(q_vals)\n",
    "    best_moves = [a for a in possible_moves if self.Q.get((state, a), 0) == max_q]\n",
    "    action = random.choice(best_moves)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjn2vgr-AY2_",
   "metadata": {
    "id": "jjn2vgr-AY2_"
   },
   "outputs": [],
   "source": [
    "class QAgentTrain(Qagent):\n",
    "    def __init__(self):\n",
    "        self.Q = {}\n",
    "        self.last_action = None\n",
    "        self.is_learning = True\n",
    "\n",
    "    def step(self, node, action):\n",
    "        if action not in node.game.possible_moves():\n",
    "\n",
    "            return node, -10\n",
    "\n",
    "        player = node.game.current_player_index\n",
    "        new_game = node.game.deep_copy()\n",
    "        new_game.make_move(action)\n",
    "        new_node = Node(new_game, parent=node, move=action)\n",
    "\n",
    "        reward = new_node.evaluate(player)\n",
    "        return new_node, reward\n",
    "\n",
    "    def choose_action(self, node, epsilon):\n",
    "        state = node.state_key()\n",
    "        possible_moves = node.game.possible_moves()\n",
    "        self.random_action = False\n",
    "        if random.random() < epsilon:\n",
    "            self.random_action = True\n",
    "            return random.choice(possible_moves)\n",
    "\n",
    "        q_vals = [self.Q.get((state, a), 0) for a in possible_moves]\n",
    "        max_q = max(q_vals)\n",
    "        best_moves = [a for a in possible_moves if self.Q.get((state, a), 0) == max_q]\n",
    "        return random.choice(best_moves)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, next_possible_moves, gamma, alpha, Q = None):\n",
    "        future_q = max([self.Q.get((next_state, a), 0) for a in next_possible_moves], default=0)\n",
    "        old_q = self.Q.get((state, action), 0)\n",
    "        self.Q[(state, action)] = old_q + alpha * (reward + gamma * future_q - old_q)\n",
    "\n",
    "    def initialize_game(self):\n",
    "        grid = [['', '', ''], ['', '', ''], ['', '', '']]\n",
    "        board = GridBoard(grid)\n",
    "        game = Game(board)\n",
    "        return Node(game)\n",
    "\n",
    "    def train_episode(self, rival, epsilon, gamma, alpha):\n",
    "        node = self.initialize_game()\n",
    "\n",
    "        while not node.is_terminal_node():\n",
    "            self.train_step(node, rival, epsilon, gamma, alpha)\n",
    "            if node.is_terminal_node():\n",
    "                break\n",
    "            node = self.next_node  # Store the new state from train_step for next loop\n",
    "\n",
    "\n",
    "    def train_step(self, node, rival, epsilon, gamma, alpha):\n",
    "        state = node.state_key()\n",
    "        action = self.choose_action(node, epsilon)\n",
    "        next_node, reward1 = self.step(node, action)\n",
    "\n",
    "\n",
    "        if rival.is_learning:\n",
    "           rival.learn_in_game_from_previous_moves(next_node, gamma, alpha)\n",
    "\n",
    "        if next_node.is_terminal_node():\n",
    "            self.learn_in_game_end(next_node, alpha)\n",
    "\n",
    "            # self.Q[(state, action)] = self.Q.get((state, action), 0) + alpha * (reward1 - self.Q.get((state, action), 0))\n",
    "            self.next_node = next_node\n",
    "            return\n",
    "\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        minimax_action = rival.choose_action(next_node, 0)\n",
    "        next_node2, reward = self.step(next_node, minimax_action)\n",
    "\n",
    "\n",
    "\n",
    "        # next_state = next_node.state_key()\n",
    "        # next_possible_moves = next_node.game.possible_moves()\n",
    "        # total_reward = reward1 + reward\n",
    "        # self.rewards.append(reward)\n",
    "\n",
    "        # self.update_q_value(state, action, total_reward, next_state, next_possible_moves, gamma, alpha)\n",
    "\n",
    "        self.learn_in_game_from_previous_moves(next_node2, gamma, alpha)\n",
    "\n",
    "\n",
    "        if rival.is_learning and next_node2.is_terminal_node():\n",
    "            # state = next_node.state_key()\n",
    "            rival.learn_in_game_end(next_node2, alpha)\n",
    "\n",
    "            # rival.Q[(state, minimax_action)] = rival.Q.get((state, minimax_action), 0) + alpha * (reward - rival.Q.get((state, minimax_action), 0))\n",
    "\n",
    "        self.next_node = next_node2\n",
    "\n",
    "    def learn_in_game_from_previous_moves(self, node : Node, gamma, alpha):\n",
    "        # total_reward = 0\n",
    "        # current_node = node\n",
    "        # player = node.game.current_player()\n",
    "        # action = node.move\n",
    "        # while current_node.parent is not None:\n",
    "        #   action, parent_node = current_node.get_parent_move()\n",
    "        #   p_player = parent_node.game.current_player()\n",
    "        #   reward = current_node.evaluate(p_player)\n",
    "        #   if p_player == player:\n",
    "        #     total_reward *= -1\n",
    "        #     total_reward += reward\n",
    "        #     break\n",
    "        #   else:\n",
    "        #     total_reward += current_node.evaluate(p_player)\n",
    "\n",
    "        #   current_node = parent_node\n",
    "\n",
    "        opponent_previous_move = node.parent\n",
    "        my_previous_move = node.parent.parent\n",
    "        if my_previous_move is None:\n",
    "          return\n",
    "\n",
    "\n",
    "        my_state = my_previous_move.state_key()\n",
    "        my_action = opponent_previous_move.move\n",
    "        opponent_state = opponent_previous_move.state_key()\n",
    "        opponent_action = node.move\n",
    "\n",
    "        _, my_reward = self.step(my_previous_move, my_action)\n",
    "        _, opponent_reward = self.step(opponent_previous_move, opponent_action)\n",
    "        total_reward = my_reward - opponent_reward\n",
    "\n",
    "        self.update_q_value(my_state, my_action, total_reward, node.state_key(), node.game.possible_moves(), gamma, alpha)\n",
    "\n",
    "\n",
    "    def learn_in_game_end(self, node: Node, alpha):\n",
    "       if node.is_terminal_node() is not True:\n",
    "        return\n",
    "\n",
    "       my_previous_move = node.parent\n",
    "       my_state = my_previous_move.state_key()\n",
    "       my_action = node.move\n",
    "       _, my_reward = self.step(my_previous_move, my_action)\n",
    "\n",
    "\n",
    "       self.Q[(my_state, my_action)] = self.Q.get((my_state, my_action), 0) + alpha * (my_reward - self.Q.get((my_state, my_action), 0))\n",
    "\n",
    "\n",
    "    def train(self, rival=None, episodes=4000, epsilon=0.1, gamma=0.95, alpha=0.1):\n",
    "        self.rewards = []\n",
    "        for episode in range(episodes):\n",
    "            self.train_episode(rival, epsilon, gamma, alpha)\n",
    "\n",
    "\n",
    "    # def choose_move(self,game, node : Node, learn = False):\n",
    "    #    if str(game.info()) != str(node.game.info()):\n",
    "    #     print('hahahah')\n",
    "    #    move = self.choose_move(node.game)\n",
    "\n",
    "    #    if learn:\n",
    "    #     self.learn_move(node)\n",
    "    #    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXsLsT4W5QE9",
   "metadata": {
    "id": "KXsLsT4W5QE9"
   },
   "source": [
    "# QV2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QNlmj-o8ev0-",
   "metadata": {
    "id": "QNlmj-o8ev0-"
   },
   "outputs": [],
   "source": [
    "class QAgentTrainV2(Qagent):\n",
    "    def __init__(self, epsilon=0.1, gamma=0.95, alpha=0.1):\n",
    "        self.Q = {}\n",
    "        self.last_action = None\n",
    "        self.is_learning = True\n",
    "\n",
    "        # epsl\n",
    "        self.epsl = (0, (0, 1))\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.rewards = []\n",
    "        self.epsch = epsilonchanger()\n",
    "\n",
    "    def step(self, node, action):\n",
    "        if action not in node.game.possible_moves():\n",
    "\n",
    "            return node, -10\n",
    "\n",
    "        player = node.game.current_player_index\n",
    "        new_game = node.game.deep_copy()\n",
    "        new_game.make_move(action)\n",
    "        new_node = Node(new_game, parent=node, move=action)\n",
    "\n",
    "        reward = new_node.evaluate(player)\n",
    "        return new_node, reward\n",
    "\n",
    "    def choose_action(self, node):\n",
    "        state = node.state_key()\n",
    "        possible_moves = node.game.possible_moves()\n",
    "        self.random_action = False\n",
    "        if random.random() < self.epsilon:\n",
    "            self.random_action = True\n",
    "            return random.choice(possible_moves)\n",
    "\n",
    "        q_vals = [self.Q.get((state, a), 0) for a in possible_moves]\n",
    "        max_q = max(q_vals)\n",
    "        best_moves = [a for a in possible_moves if self.Q.get((state, a), 0) == max_q]\n",
    "        return random.choice(best_moves)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, next_possible_moves):\n",
    "        future_q = max([self.Q.get((next_state, a), 0) for a in next_possible_moves], default=0)\n",
    "        old_q = self.Q.get((state, action), 0)\n",
    "        self.Q[(state, action)] = old_q + self.alpha * (reward + self.gamma * future_q - old_q)\n",
    "\n",
    "    def initialize_game(self):\n",
    "        grid = [['', '', ''], ['', '', ''], ['', '', '']]\n",
    "        board = GridBoard(grid)\n",
    "        game = Game(board)\n",
    "        return Node(game)\n",
    "\n",
    "    def train_episode(self, rival):\n",
    "        node = self.initialize_game()\n",
    "\n",
    "        while not node.is_terminal_node():\n",
    "            self.train_step(node, rival)\n",
    "            if node.is_terminal_node():\n",
    "                break\n",
    "            node = self.next_node\n",
    "\n",
    "\n",
    "    def train_step(self, node, rival):\n",
    "        state = node.state_key()\n",
    "        action = self.choose_action(node)\n",
    "        next_node, reward1 = self.step(node, action)\n",
    "\n",
    "\n",
    "        if rival.is_learning:\n",
    "           rival.learn_in_game_from_previous_moves(next_node)\n",
    "\n",
    "        if next_node.is_terminal_node():\n",
    "            self.learn_in_game_end(next_node)\n",
    "\n",
    "            self.next_node = next_node\n",
    "            return\n",
    "\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        minimax_action = rival.choose_action(next_node) # when choose_action agent is worse when choose_move\n",
    "        next_node2, reward = self.step(next_node, minimax_action)\n",
    "\n",
    "\n",
    "\n",
    "        self.learn_in_game_from_previous_moves(next_node2)\n",
    "\n",
    "\n",
    "        if rival.is_learning and next_node2.is_terminal_node():\n",
    "            rival.learn_in_game_end(next_node2)\n",
    "\n",
    "\n",
    "        self.next_node = next_node2\n",
    "\n",
    "    def learn_in_game_from_previous_moves(self, node : Node):\n",
    "        if node is None:\n",
    "          return\n",
    "        total_reward = 0\n",
    "        current_node = node\n",
    "        player = node.game.current_player_index\n",
    "        action = node.move\n",
    "        parent_node = None\n",
    "        while current_node.parent is not None:\n",
    "          action, parent_node = current_node.get_parent_move()\n",
    "          if parent_node is None:\n",
    "            return\n",
    "          p_player = parent_node.game.current_player_index\n",
    "          reward = current_node.evaluate(p_player)\n",
    "          if p_player == player:\n",
    "            total_reward *= -1\n",
    "            total_reward += reward\n",
    "            break\n",
    "          else:\n",
    "            total_reward += current_node.evaluate(p_player)\n",
    "\n",
    "          current_node = parent_node\n",
    "        if parent_node is None:\n",
    "            return\n",
    "\n",
    "        my_state = parent_node.state_key()\n",
    "        my_action = action\n",
    "\n",
    "        # opponent_previous_move = node.parent\n",
    "        # if opponent_previous_move is None:\n",
    "\n",
    "        #   return\n",
    "        # my_previous_move = node.parent.parent\n",
    "        # if my_previous_move is None:\n",
    "        #   return\n",
    "\n",
    "        # my_state = my_previous_move.state_key()\n",
    "        # my_action = opponent_previous_move.move\n",
    "        # opponent_state = opponent_previous_move.state_key()\n",
    "        # opponent_action = node.move\n",
    "\n",
    "        # _, my_reward = self.step(my_previous_move, my_action)\n",
    "        # _, opponent_reward = self.step(opponent_previous_move, opponent_action)\n",
    "        # total_reward = my_reward - opponent_reward\n",
    "\n",
    "        if node.is_terminal_node():\n",
    "          self.Q[(my_state, my_action)] = self.Q.get((my_state, my_action), 0) + self.alpha * (total_reward - self.Q.get((my_state, my_action), 0))\n",
    "        else:\n",
    "          self.update_q_value(my_state, my_action, total_reward, node.state_key(), node.game.possible_moves())\n",
    "\n",
    "    def learn_move(self, node : Node):\n",
    "      if node.is_terminal_node():\n",
    "        self.learn_in_game_end(node)\n",
    "      else:\n",
    "        self.learn_in_game_from_previous_moves(node)\n",
    "\n",
    "\n",
    "    def learn_in_game_end(self, node: Node):\n",
    "       if node.is_terminal_node() is not True:\n",
    "        return\n",
    "\n",
    "       my_previous_move = node.parent\n",
    "       my_state = my_previous_move.state_key()\n",
    "       my_action = node.move\n",
    "       _, my_reward = self.step(my_previous_move, my_action)\n",
    "\n",
    "\n",
    "       self.Q[(my_state, my_action)] = self.Q.get((my_state, my_action), 0) + self.alpha * (my_reward - self.Q.get((my_state, my_action), 0))\n",
    "\n",
    "\n",
    "    def train(self, rival=None, episodes=4000):\n",
    "        self.rewards = []\n",
    "        for episode in range(episodes):\n",
    "            self.train_episode(rival)\n",
    "\n",
    "            self.epsilon = self.epsch.add()\n",
    "            rival.epsilon = self.epsch.next_change_table()\n",
    "\n",
    "    def choose_move(self, node, *args):\n",
    "       move = super().choose_move(node, *args)\n",
    "       if args[0] is True:\n",
    "        self.learn_move(node)\n",
    "       return move\n",
    "\n",
    "    # def choose_move(self, node, learn = False):\n",
    "    #    su\n",
    "    #    move = self.choose_move(node, Fa)\n",
    "    #    if learn:\n",
    "    #     self.learn_move(node)\n",
    "    #    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8VPTPhsjAJZ",
   "metadata": {
    "id": "a8VPTPhsjAJZ"
   },
   "outputs": [],
   "source": [
    "class epsilonchanger:\n",
    "  def __init__(self, episodes = 1, change_table = [0.1, 0]) -> None:\n",
    "     self.episodes = episodes\n",
    "     self.current_episode = 0\n",
    "     self.change_table = change_table\n",
    "     self.current_index = 0\n",
    "\n",
    "  def add(self):\n",
    "    self.current_episode += 1\n",
    "    if self.current_episode == self.episodes:\n",
    "      self.current_episode = 0\n",
    "      self.current_index += 1\n",
    "      if self.current_index == len(self.change_table):\n",
    "        self.current_index = 0\n",
    "\n",
    "    return self.change_table[self.current_index]\n",
    "\n",
    "  def next_change_table(self):\n",
    "    return self.change_table[(self.current_index + 1) % len(self.change_table)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tdZEj0M--wym",
   "metadata": {
    "id": "tdZEj0M--wym"
   },
   "source": [
    "Agenty ktÃ³re obserwujÄ… losowe ruchy przeciwnika i same nie wykonujÄ… losowych ruchÃ³w sÄ… lepsze -> zabawa z epsilonem\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dhu7bAM84vqJ",
   "metadata": {
    "id": "dhu7bAM84vqJ"
   },
   "source": [
    "# Nowa sekcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L_VGsC-4ALd6",
   "metadata": {
    "id": "L_VGsC-4ALd6"
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = QAgentTrainV2()\n",
    "    agent1 = QAgentTrainV2()\n",
    "\n",
    "    agent.train(agent1, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jh69p0G76I4M",
   "metadata": {
    "id": "Jh69p0G76I4M"
   },
   "source": [
    "Agent lepiej siÄ™Â uczy gdy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13-EyMeyEYQt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13-EyMeyEYQt",
    "outputId": "68f8bc3a-7686-46af-9bff-f8a76e0d59ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 0, 'lose': 0, 'draw': 5000},\n",
       " 'Bob': {'win': 0, 'lose': 0, 'draw': 5000}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", agent)\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", memoagent(memo))\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JE_TynzUHxdu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JE_TynzUHxdu",
    "outputId": "a7219d14-4157-427f-f5b3-8a956ca8ae90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 40, 'lose': 0, 'draw': 4960},\n",
       " 'Bob': {'win': 0, 'lose': 40, 'draw': 4960}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", memoagent(memo))\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", agent1)\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tecjU8gKTcGN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tecjU8gKTcGN",
    "outputId": "2db16571-1e32-4a6d-e0ed-271264034f31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 1710, 'lose': 2688, 'draw': 602},\n",
       " 'Bob': {'win': 2688, 'lose': 1710, 'draw': 602}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", random_player())\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", agent1)\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jiEXt0VZXoyp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiEXt0VZXoyp",
    "outputId": "27436e43-7088-4c25-e5a7-dc7d514292b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 4831, 'lose': 41, 'draw': 128},\n",
       " 'Bob': {'win': 41, 'lose': 4831, 'draw': 128}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", agent)\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", random_player())\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4k4J8n5xZya9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k4J8n5xZya9",
    "outputId": "95713a30-552f-43e4-8dfb-dc351df6ea0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 0, 'lose': 0, 'draw': 5000},\n",
       " 'Bob': {'win': 0, 'lose': 0, 'draw': 5000}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", agent)\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", agent1)\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kEnxMJ16jhf8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEnxMJ16jhf8",
    "outputId": "6ae5fb5f-f9d9-4d3e-cad6-47ea36df3965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ala': {'win': 4843, 'lose': 0, 'draw': 157},\n",
       " 'Bob': {'win': 0, 'lose': 4843, 'draw': 157}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    player1 = Player(\"Ala\", 0 , \"X\", memoagent(memo))\n",
    "    player2 = Player(\"Bob\", 0 , \"S\", random_player())\n",
    "    players = [player1, player2]\n",
    "    veryfiy = VeryficationV2(players)\n",
    "    veryfiy.verify(5000)\n",
    "    veryfiy.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UhtaKnI3Et9X",
   "metadata": {
    "id": "UhtaKnI3Et9X"
   },
   "outputs": [],
   "source": [
    "# agent.train(agent1, 8000)\n",
    "# agent.train(random_player(), 4000)\n",
    "# agent.train(memoagent(memo), 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aYxNNVWRKJy",
   "metadata": {
    "id": "6aYxNNVWRKJy"
   },
   "source": [
    "# Turnament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DD7k4LohwYDo",
   "metadata": {
    "id": "DD7k4LohwYDo"
   },
   "source": [
    "# Nowa sekcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2WfahukGwV5G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WfahukGwV5G",
    "outputId": "7bd915b0-aaf9-42e9-a888-d6a72311fd90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_block_column (__main__.TestTicTacToeAgent.test_block_column) ... ERROR\n",
      "test_block_opponent_win (__main__.TestTicTacToeAgent.test_block_opponent_win) ... ERROR\n",
      "test_fork_move (__main__.TestTicTacToeAgent.test_fork_move) ... ERROR\n",
      "test_no_win_play_first_free (__main__.TestTicTacToeAgent.test_no_win_play_first_free) ... ERROR\n",
      "test_win_in_column (__main__.TestTicTacToeAgent.test_win_in_column) ... ERROR\n",
      "test_win_in_diagonal (__main__.TestTicTacToeAgent.test_win_in_diagonal) ... ERROR\n",
      "test_win_in_row (__main__.TestTicTacToeAgent.test_win_in_row) ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_block_column (__main__.TestTicTacToeAgent.test_block_column)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 47, in test_block_column\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_block_opponent_win (__main__.TestTicTacToeAgent.test_block_opponent_win)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 40, in test_block_opponent_win\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_fork_move (__main__.TestTicTacToeAgent.test_fork_move)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 54, in test_fork_move\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_win_play_first_free (__main__.TestTicTacToeAgent.test_no_win_play_first_free)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 33, in test_no_win_play_first_free\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_win_in_column (__main__.TestTicTacToeAgent.test_win_in_column)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 19, in test_win_in_column\n",
      "    move = agent_move(board, 'O')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_win_in_diagonal (__main__.TestTicTacToeAgent.test_win_in_diagonal)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 26, in test_win_in_diagonal\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_win_in_row (__main__.TestTicTacToeAgent.test_win_in_row)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-44-882282547.py\", line 12, in test_win_in_row\n",
      "    move = agent_move(board, 'X')\n",
      "           ^^^^^^^^^^\n",
      "NameError: name 'agent_move' is not defined\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.011s\n",
      "\n",
      "FAILED (errors=7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7d27554c98d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    grid = [\n",
    "        ['', '', ''],\n",
    "        ['', '', ''],\n",
    "        ['', '', '']\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    board = GridBoard(grid)\n",
    "    game = Game(board)\n",
    "\n",
    "    mem =  memoagent(memo)\n",
    "    mem.choose_move(Node(game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ESLj3Fd-yiRk",
   "metadata": {
    "id": "ESLj3Fd-yiRk"
   },
   "outputs": [],
   "source": [
    "    mem =  memoagent(memo)\n",
    "    random_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U_2FhjG3E4yq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_2FhjG3E4yq",
    "outputId": "8f0fb9c5-21fe-4d3c-a243-aeb4cf3bc8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Test failed for memo: memo failed: expected (0,2), got (2, 0)\n",
      "âœ… random passed\n",
      "âŒ Test failed for Qagent: Qagent failed: expected (0,2), got (1, 0)\n"
     ]
    }
   ],
   "source": [
    "    agents = {\n",
    "        \"memo\": memoagent(memo=memo),\n",
    "        \"random\": random_player(),\n",
    "        \"Qagent\": agent\n",
    "    }\n",
    "\n",
    "    for name, agent in agents.items():\n",
    "        try:\n",
    "            grid = [['X', 'X', ''], ['', '', ''], ['', 'S', 'S']]\n",
    "            board = GridBoard(grid)\n",
    "            game = Game(board)\n",
    "            node = Node(game)\n",
    "\n",
    "            move = agent.choose_move(node)\n",
    "            assert move == (0, 2), f\"{name} failed: expected (0,2), got {move}\"\n",
    "            print(f\"âœ… {name} passed\")\n",
    "\n",
    "        except AssertionError as e:\n",
    "            print(f\"âŒ Test failed for {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Cjv_ekzjF12M",
    "wzwMQea41JuS",
    "bMwsSIGtOSRY",
    "1NGNAeCfOZyv",
    "NOwL2g_nGgdM",
    "Ll6sbTNnPBaU",
    "d-WUltg7RbCu"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
